import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
import base64
from io import BytesIO
from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report, log_loss, precision_score, recall_score, f1_score
import plotly.graph_objects as go
import plotly.express as px
from PIL import Image
from plotly.subplots import make_subplots

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Modelando o Risco de Cr√©dito",
    page_icon="üí∞",
    layout="wide"
)

# T√≠tulo e descri√ß√£o da aplica√ß√£o
st.title("Ferramenta Interativa de Modelagem do Risco de Cr√©dito")
st.markdown("""
Esta ferramenta demonstra como funciona a modelagem de risco de cr√©dito utilizando regress√£o log√≠stica.
Voc√™ pode selecionar vari√°veis, treinar um modelo e analisar potenciais tomadores de empr√©stimo.
""")

# Fun√ß√£o para carregar dados
@st.cache_data
def load_data():
    # Em uma aplica√ß√£o real, substitua estes pelos caminhos dos arquivos reais
    try:
        training_sample = pd.read_csv('training_sample.csv')
        testing_sample = pd.read_csv('testing_sample.csv')
        return training_sample, testing_sample
    except:
        # Dados de demonstra√ß√£o para quando os arquivos n√£o estiverem dispon√≠veis
        st.warning("Usando dados de demonstra√ß√£o. Em produ√ß√£o, conecte-se a conjuntos de dados reais.")
        # Criar dados sint√©ticos de treinamento
        np.random.seed(42)
        n_training = 250000
        n_testing = 20000
        
        # Caracter√≠sticas
        loan_amnt = np.random.uniform(1000, 35000, n_training)
        int_rate = np.random.uniform(5, 25, n_training)
        annual_inc = np.random.uniform(20000, 150000, n_training)
        dti = np.random.uniform(0, 40, n_training)  # rela√ß√£o d√≠vida-renda
        delinq_2yrs = np.random.poisson(0.5, n_training)
        fico_range_low = np.random.normal(700, 50, n_training).astype(int)
        
        # Vari√°veis dummy de grau (codifica√ß√£o one-hot)
        grade_probs = [0.30, 0.25, 0.20, 0.15, 0.05, 0.03, 0.02]  # Distribui√ß√£o de probabilidade
        grades = np.random.choice(['A', 'B', 'C', 'D', 'E', 'F', 'G'], n_training, p=grade_probs)
        grade_A = (grades == 'A').astype(int)
        grade_B = (grades == 'B').astype(int)
        grade_C = (grades == 'C').astype(int)
        grade_D = (grades == 'D').astype(int)
        grade_E = (grades == 'E').astype(int)
        grade_F = (grades == 'F').astype(int)
        grade_G = (grades == 'G').astype(int)
        
        # Gerar loan_status (vari√°vel alvo) com rela√ß√£o realista com as caracter√≠sticas
        # FICO mais alto, valor do empr√©stimo menor, taxa de juros menor, renda maior = menor probabilidade de inadimpl√™ncia
        logit = -5 + 0.00005 * loan_amnt + 0.1 * int_rate - 0.00001 * annual_inc + 0.05 * dti + \
                0.5 * delinq_2yrs - 0.01 * fico_range_low + 0 * grade_A + 0.2 * grade_B + \
                0.5 * grade_C + 0.8 * grade_D + 1.1 * grade_E + 1.4 * grade_F + 1.7 * grade_G
        
        prob_default = 1 / (1 + np.exp(-logit))
        loan_status = np.random.binomial(1, prob_default)
        
        # Garantir propor√ß√£o de 80% bem-sucedidos, 20% inadimplentes reamostrando
        successful_indices = np.where(loan_status == 0)[0]
        default_indices = np.where(loan_status == 1)[0]
        
        target_successful_count = int(0.8 * n_training)
        target_default_count = n_training - target_successful_count
        
        if len(successful_indices) > target_successful_count:
            successful_indices = np.random.choice(successful_indices, target_successful_count, replace=False)
        else:
            # Precisa criar mais empr√©stimos bem-sucedidos
            additional_needed = target_successful_count - len(successful_indices)
            loan_status[np.random.choice(default_indices, additional_needed, replace=False)] = 0
            successful_indices = np.where(loan_status == 0)[0]
            default_indices = np.where(loan_status == 1)[0]
        
        if len(default_indices) > target_default_count:
            default_indices = np.random.choice(default_indices, target_default_count, replace=False)
        else:
            # Precisa criar mais inadimplentes
            additional_needed = target_default_count - len(default_indices)
            loan_status[np.random.choice(successful_indices, additional_needed, replace=False)] = 1
        
        # Criar DataFrame
        training_sample = pd.DataFrame({
            'id': range(1, n_training + 1),
            'loan_amnt': loan_amnt,
            'int_rate': int_rate,
            'annual_inc': annual_inc,
            'dti': dti,
            'delinq_2yrs': delinq_2yrs,
            'fico_range_low': fico_range_low,
            'grade_A': grade_A,
            'grade_B': grade_B,
            'grade_C': grade_C,
            'grade_D': grade_D,
            'grade_E': grade_E,
            'grade_F': grade_F,
            'grade_G': grade_G,
            'loan_status': loan_status
        })
        
        # Criar amostra de teste (estrutura similar mas sem loan_status)
        # Usar as mesmas distribui√ß√µes mas amostras aleat√≥rias diferentes
        loan_amnt_test = np.random.uniform(1000, 35000, n_testing)
        int_rate_test = np.random.uniform(5, 25, n_testing)
        annual_inc_test = np.random.uniform(20000, 150000, n_testing)
        dti_test = np.random.uniform(0, 40, n_testing)
        delinq_2yrs_test = np.random.poisson(0.5, n_testing)
        fico_range_low_test = np.random.normal(700, 50, n_testing).astype(int)
        
        grades_test = np.random.choice(['A', 'B', 'C', 'D', 'E', 'F', 'G'], n_testing, p=grade_probs)
        grade_A_test = (grades_test == 'A').astype(int)
        grade_B_test = (grades_test == 'B').astype(int)
        grade_C_test = (grades_test == 'C').astype(int)
        grade_D_test = (grades_test == 'D').astype(int)
        grade_E_test = (grades_test == 'E').astype(int)
        grade_F_test = (grades_test == 'F').astype(int)
        grade_G_test = (grades_test == 'G').astype(int)
        
        testing_sample = pd.DataFrame({
            'id': range(1, n_testing + 1),
            'loan_amnt': loan_amnt_test,
            'int_rate': int_rate_test,
            'annual_inc': annual_inc_test,
            'dti': dti_test,
            'delinq_2yrs': delinq_2yrs_test,
            'fico_range_low': fico_range_low_test,
            'grade_A': grade_A_test,
            'grade_B': grade_B_test,
            'grade_C': grade_C_test,
            'grade_D': grade_D_test,
            'grade_E': grade_E_test,
            'grade_F': grade_F_test,
            'grade_G': grade_G_test
        })
        
        return training_sample, testing_sample

# Carregar dados
training_sample, testing_sample = load_data()

# Exibir vis√£o geral dos dados
with st.expander("Vis√£o Geral dos Dados"):
    st.subheader("Base de Treinamento")
    st.write(f"Dimens√µes: {training_sample.shape}")
    
    # Estiliza√ß√£o do DataFrame usando Pandas
    def style_table(df):
        df = df.reset_index(drop=True)

        # Criar lista de nomes de colunas para as colunas 2 a 8
        columns_to_format = df.columns[2:8]

        return (
            df.style
            .set_table_styles(
                [{
                    'selector': 'thead th',
                    'props': [('font-weight', 'bold'),
                            ('border-style', 'solid'),
                            ('border-width', '0px 0px 2px 0px'),
                            ('border-color', 'black')]
                }, {
                    'selector': 'thead th:not(:first-child)',
                    'props': [('text-align', 'center')]  # Centralizar todos os cabe√ßalhos exceto o primeiro
                }, {
                    'selector': 'thead th:last-child',
                    'props': [('color', 'black')]  # Fazer o cabe√ßalho da √∫ltima coluna preto
                }, {
                    'selector': 'td',
                    'props': [('border-style', 'solid'),
                            ('border-width', '0px 0px 1px 0px'),
                            ('border-color', 'black'),
                            ('text-align', 'center')]
                }, {
                    'selector': 'th',
                    'props': [('border-style', 'solid'),
                            ('border-width', '0px 0px 1px 0px'),
                            ('border-color', 'black'),
                            ('text-align', 'left')]
                }]
            )
            .set_properties(**{'padding': '2px', 'font-size': '15px'})
            .format({col: "{:.2f}" for col in columns_to_format})  # Formatar colunas para 2 casas decimais
        )

    # Exibindo no Streamlit
    def main():
        styled_html = style_table(training_sample.head()).to_html(index=False, escape=False)
        centered_html = f'''
        <div style="display: flex; justify-content: left;">
            {styled_html}
        '''  # Fechar corretamente a tag div
        st.markdown(centered_html, unsafe_allow_html=True)

    if __name__ == '__main__':
        main()
    
    
    st.subheader("Base de Valida√ß√£o")
    st.write(f"Dimens√µes: {testing_sample.shape}")

    # Estiliza√ß√£o do DataFrame usando Pandas
    def style_table(df):
        df = df.reset_index(drop=True)

        # Criar lista de nomes de colunas para as colunas 2 a 8
        columns_to_format = df.columns[2:8]

        return (
            df.style
            .set_table_styles(
                [{
                    'selector': 'thead th',
                    'props': [('font-weight', 'bold'),
                            ('border-style', 'solid'),
                            ('border-width', '0px 0px 2px 0px'),
                            ('border-color', 'black')]
                }, {
                    'selector': 'thead th:not(:first-child)',
                    'props': [('text-align', 'center')]  # Centralizar todos os cabe√ßalhos exceto o primeiro
                }, {
                    'selector': 'thead th:last-child',
                    'props': [('color', 'black')]  # Fazer o cabe√ßalho da √∫ltima coluna preto
                }, {
                    'selector': 'td',
                    'props': [('border-style', 'solid'),
                            ('border-width', '0px 0px 1px 0px'),
                            ('border-color', 'black'),
                            ('text-align', 'center')]
                }, {
                    'selector': 'th',
                    'props': [('border-style', 'solid'),
                            ('border-width', '0px 0px 1px 0px'),
                            ('border-color', 'black'),
                            ('text-align', 'left')]
                }]
            )
            .set_properties(**{'padding': '2px', 'font-size': '15px'})
            .format({col: "{:.2f}" for col in columns_to_format})  # Formatar colunas para 2 casas decimais
        )

    # Exibindo no Streamlit
    def main():
        styled_html = style_table(testing_sample.head()).to_html(index=False, escape=False)
        centered_html = f'''
        <div style="display: flex; justify-content: left;">
            {styled_html}
        '''  # Fechar corretamente a tag div
        st.markdown(centered_html, unsafe_allow_html=True)

    if __name__ == '__main__':
        main()

    
    # Exibir distribui√ß√£o de classes
    st.subheader("Distribui√ß√£o de Classes nos Dados de Treinamento")
    fig, ax = plt.subplots(figsize=(6, 4))
    class_counts = training_sample['loan_status'].value_counts()
    ax.bar(['Pago (0)', 'Inadimplente (1)'], class_counts.values)
    ax.set_ylabel('Contagem')
    ax.set_title('Distribui√ß√£o do Status do Empr√©stimo')
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    for i, v in enumerate(class_counts.values):
        ax.text(i, v + 3000, f"{v} ({v/len(training_sample)*100:.1f}%)", ha='center')
    col1, col2, col3 = st.columns([1, 5, 1])
    with col2:
        st.pyplot(fig)        

# Sele√ß√£o de caracter√≠sticas
st.header("1. Sele√ß√£o de Vari√°veis")
st.write("Selecione as vari√°veis que deseja incluir em seu modelo de regress√£o log√≠stica:")

# Obter caracter√≠sticas dispon√≠veis (excluindo id e vari√°vel alvo)
available_features = [col for col in training_sample.columns 
                     if col not in ['id', 'loan_status']]

# Agrupar caracter√≠sticas por categoria para melhor organiza√ß√£o
numerical_features = ['loan_amnt', 'int_rate', 'annual_inc', 'dti', 'delinq_2yrs', 'fico_range_low']
categorical_features = [col for col in available_features if col.startswith('grade_')]

with st.container():
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Vari√°veis Num√©ricas")
        selected_numerical = []
        for feature in numerical_features:
            if st.checkbox(f"{feature}", value=True):
                selected_numerical.append(feature)
    
    with col2:
        st.subheader("Vari√°veis Categ√≥ricas")
        selected_categorical = []
        for feature in categorical_features:
            if st.checkbox(f"{feature}", value=True):
                selected_categorical.append(feature)

selected_features = selected_numerical + selected_categorical

if not selected_features:
    st.warning("Por favor, selecione ao menos uma vari√°vel para construir o modelo.")
else:
    st.success(f"Selecionadas {len(selected_features)} vari√°veis: {', '.join(selected_features)}")

# Treinamento do modelo
st.header("2. Treinamento do Modelo")

if st.button("Treinar Modelo de Regress√£o Log√≠stica", key=1, disabled=not selected_features):
    if not selected_features:
        st.error("Nenhuma vari√°vel selecionada. Por favor, selecione ao menos uma vari√°vel.")
    else:
        with st.spinner("Treinando o modelo..."):
            # Preparar dados
            X = training_sample[selected_features]
            y = training_sample['loan_status']
            
            # Divis√£o treino-teste
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.3, random_state=42, stratify=y
            )
            
            st.session_state.X_train = X_train
            st.session_state.X_test = X_test
            st.session_state.y_train = y_train
            st.session_state.y_test = y_test
            
            # Ajustar modelo de regress√£o log√≠stica
            model = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)
            model.fit(X_train, y_train)
            st.session_state.model = model
            
            # Previs√µes
            y_pred_proba = model.predict_proba(X_test)[:, 1]
            y_pred = model.predict(X_test)
            st.session_state.y_pred = y_pred
            st.session_state.y_pred_proba = y_pred_proba
            
            # Usar diretamente LogisticRegression do sklearn
            # Isso evita o processo problem√°tico de ajuste do statsmodels
            st.session_state.model_coef = model.coef_[0]
            st.session_state.model_intercept = model.intercept_[0]
            
            # Criar estat√≠sticas de resumo personalizadas
            from sklearn.metrics import log_loss
            train_pred_proba = model.predict_proba(X_train)[:, 1]
            train_log_loss = log_loss(y_train, train_pred_proba)
            
            # Armazenar para exibi√ß√£o posterior
            st.session_state.custom_summary = {
                'features': selected_features,
                'coefficients': model.coef_[0],
                'intercept': model.intercept_[0],
                'train_log_loss': train_log_loss,
                'train_accuracy': model.score(X_train, y_train),
                'test_accuracy': model.score(X_test, y_test)
            }
            
            # Calcular equa√ß√£o para exibi√ß√£o
            coefficients = model.coef_[0]
            intercept = model.intercept_[0]
            st.session_state.coefficients = coefficients
            st.session_state.intercept = intercept
            st.session_state.selected_features = selected_features
            
            st.success("Modelo treinado com sucesso!")
            st.session_state.model_trained = True
            
            # Armazenar informa√ß√µes das caracter√≠sticas para uso posterior com amostra de teste
            st.session_state.original_features = selected_features

# Exibi√ß√£o de resultados - mostrar apenas se o modelo foi treinado
if 'model_trained' in st.session_state and st.session_state.model_trained:
    st.header("Resultados do Modelo")
    
    # Adicionar seletor de limiar no topo da se√ß√£o de resultados
    st.subheader("1. Configura√ß√£o do Limiar de Decis√£o")
    with st.container():
        st.markdown("""
        **Configure o limiar de decis√£o para aprova√ß√£o/rejei√ß√£o de empr√©stimos:**
        - Empr√©stimos com probabilidade prevista **abaixo** deste limiar ser√£o **aprovados**
        - Empr√©stimos com probabilidade prevista **acima** deste limiar ser√£o **rejeitados**
        """)
        
        # Slider do limiar
        decision_threshold = st.slider(
            "Limiar de Decis√£o (Probabilidade de Inadimpl√™ncia)",
            min_value=0.1,
            max_value=0.9,
            value=0.5,
            step=0.01,
            help="Ajuste este limiar com base em seu apetite ao risco. Valores menores aprovam mais empr√©stimos mas aumentam o risco de inadimpl√™ncia."
        )
        
        # Armazenar limiar no session state
        st.session_state.decision_threshold = decision_threshold
        
        # Mostrar impacto da mudan√ßa de limiar
        col1, col2, col3 = st.columns(3)
        
        with col1:
            approved_at_threshold = (st.session_state.y_pred_proba < decision_threshold).sum()
            st.metric(
                "Empr√©stimos que seriam Aprovados", 
                f"{approved_at_threshold} ({approved_at_threshold/len(st.session_state.y_pred_proba)*100:.1f}%)",
                help="N√∫mero de empr√©stimos do conjunto de teste que seriam aprovados neste limiar"
            )
        
        with col2:
            rejected_at_threshold = (st.session_state.y_pred_proba >= decision_threshold).sum()
            st.metric(
                "Empr√©stimos que seriam Rejeitados", 
                f"{rejected_at_threshold} ({rejected_at_threshold/len(st.session_state.y_pred_proba)*100:.1f}%)",
                help="N√∫mero de empr√©stimos do conjunto de teste que seriam rejeitados neste limiar"
            )
            
        with col3:
            # Calcular precis√£o e recall neste limiar
            y_pred_at_threshold = (st.session_state.y_pred_proba >= decision_threshold).astype(int)
            if y_pred_at_threshold.sum() > 0:
                precision_at_threshold = precision_score(st.session_state.y_test, y_pred_at_threshold)
                st.metric(
                    "Precis√£o neste Limiar", 
                    f"{precision_at_threshold:.3f}",
                    help="Dos empr√©stimos previstos como inadimplentes, qual porcentagem realmente ficou inadimplente"
                )
            else:
                st.metric("Precis√£o neste Limiar", "N/A", help="Nenhum empr√©stimo previsto como inadimplente neste limiar")

    
    # 1. Curva de Regress√£o Log√≠stica
    st.subheader("2. Regress√£o Log√≠stica - Curva-S")
    with st.container():
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Ordenar probabilidades e valores reais para plotagem
        sorted_indices = np.argsort(st.session_state.y_pred_proba)
        sorted_probs = st.session_state.y_pred_proba[sorted_indices]
        sorted_actuals = st.session_state.y_test.values[sorted_indices]
        
        # Plotar a curva log√≠stica
        ax.plot(range(len(sorted_probs)), sorted_probs, 'b-', linewidth=2)
        
        # Adicionar observa√ß√µes reais como pontos (com jitter para visibilidade)
        y_jittered = sorted_actuals + np.random.normal(0, 0.02, len(sorted_actuals))
        ax.scatter(range(len(sorted_probs)), y_jittered, c='r', alpha=0.1, s=1)
        
        ax.set_xlabel('Observa√ß√µes (ordenadas pela probabilidade prevista)')
        ax.set_ylabel('Probabilidade de Inadimpl√™ncia')
        ax.set_title('Regress√£o Log√≠stica - Curva-S')
        ax.grid(True, alpha=0.3)
        
        # Adicionar linha horizontal no limiar definido pelo usu√°rio
        ax.axhline(y=decision_threshold, color='green', linestyle='--', alpha=0.7, linewidth=2)
        ax.text(len(sorted_probs)*0.02, decision_threshold + 0.02, f'Limiar de Decis√£o (p={decision_threshold:.2f})', color='green', fontweight='bold')

        col1, col2, col3 = st.columns([1, 6, 1])
        with col2:
            st.pyplot(fig)        
        
        st.markdown(f"""
        **Interpreta√ß√£o:** A curva em S mostra como a probabilidade de inadimpl√™ncia prevista pelo modelo varia entre todas as observa√ß√µes.
        - Linha azul: Probabilidades previstas (ordenadas da menor para a maior)
        - Pontos vermelhos: Resultados reais (0=pago, 1=inadimplente)
        - Linha verde: Limiar de decis√£o (definido pelo usu√°rio: {decision_threshold:.2f})
        
        Com o limiar atual de {decision_threshold:.2f}:
        - Empr√©stimos com probabilidade < {decision_threshold:.2f} ser√£o **aprovados**
        - Empr√©stimos com probabilidade ‚â• {decision_threshold:.2f} ser√£o **rejeitados**
        
        Em um bom modelo, √© desej√°vel que a maioria dos pontos esteja agrupada no canto inferior esquerdo 
        (pagamentos corretamente previstos) e no canto superior direito (inadimpl√™ncias corretamente previstas).
        """)
    
    # 2. Curva ROC
    st.subheader("3. Curva ROC")
    with st.container():
        fpr, tpr, thresholds = roc_curve(st.session_state.y_test, st.session_state.y_pred_proba)
        roc_auc = auc(fpr, tpr)
        
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(fpr, tpr, 'b-', linewidth=2, label=f'Curva ROC (AUC = {roc_auc:.3f})')
        ax.plot([0, 1], [0, 1], 'r--', linewidth=1, label='Classificador Aleat√≥rio')
        ax.set_xlabel('Taxa de Falsos Positivos (1 - Especificidade)')
        ax.set_ylabel('Taxa de Verdadeiros Positivos (Sensibilidade)')
        ax.set_title('Curva ROC (Receiver Operating Characteristic)')
        ax.legend(loc='lower right')
        ax.grid(True, alpha=0.3)
        col1, col2, col3 = st.columns([1, 6, 1])
        with col2:
            st.pyplot(fig)        
        
        st.metric("Score AUC", f"{roc_auc:.3f}")
        st.markdown(f"""
        **Interpreta√ß√£o:** A curva ROC mostra o trade-off entre sensibilidade e especificidade.
        - AUC (√Årea Sob a Curva): {roc_auc:.3f} (quanto maior melhor, 1.0 √© perfeito, 0.5 √© aleat√≥rio)

        Quanto mais pr√≥xima a curva estiver do canto superior esquerdo, melhor √© a capacidade do modelo de
        diferenciar entre pagamentos e inadimpl√™ncias. Uma AUC de:

        * 0,9 a 1,0: Discrimina√ß√£o excelente
        * 0,8 a 0,9: Discrimina√ß√£o boa
        * 0,7 a 0,8: Discrimina√ß√£o razo√°vel
        * 0,6 a 0,7: Discrimina√ß√£o fraca
        * 0,5 a 0,6: Discrimina√ß√£o falha
        """)
    
    # 3. Matriz de Confus√£o (atualizada para usar limiar do usu√°rio)
    st.subheader("4. Matriz de Confus√£o")
    with st.container():
        # Recalcular previs√µes usando limiar definido pelo usu√°rio
        y_pred_user_threshold = (st.session_state.y_pred_proba >= decision_threshold).astype(int)
        cm = confusion_matrix(st.session_state.y_test, y_pred_user_threshold)
        
        # Calcular m√©tricas
        tn, fp, fn, tp = cm.ravel()
        accuracy = (tp + tn) / (tp + tn + fp + fn)
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                    xticklabels=['Previsto Pago', 'Previsto Inadimplente'],
                    yticklabels=['Realmente Pago', 'Realmente Inadimplente'])
        ax.set_xlabel('R√≥tulo Previsto')
        ax.set_ylabel('R√≥tulo Verdadeiro')
        ax.set_title(f'Matriz de Confus√£o (Limiar = {decision_threshold:.2f})')
        col1, col2, col3 = st.columns([1, 6, 1])
        with col2:
            st.pyplot(fig)        
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown(f"""
            **M√©tricas no Limiar {decision_threshold}:**
            - **Acur√°cia:** {accuracy:.3f}
            - **Precis√£o:** {precision:.3f}
            - **Recall (Sensibilidade):** {recall:.3f}
            - **Especificidade:** {specificity:.3f}
            - **F1 Score:** {f1:.3f}
            """)
            
        with col2:
            st.markdown("""
            **Defini√ß√µes:**
            - **Verdadeiros Negativos (TN):** Pagamentos corretamente previstos
            - **Falsos Positivos (FP):** Inadimpl√™ncias incorretamente previstas
            - **Falsos Negativos (FN):** Pagamentos incorretamente previstos
            - **Verdadeiros Positivos (TP):** Inadimpl√™ncias corretamente previstas
            - **Precis√£o:** Propor√ß√£o de inadimpl√™ncias previstas que eram inadimpl√™ncias reais
            - **Recall:** Propor√ß√£o de inadimpl√™ncias reais que foram corretamente previstas
            """)

        # Explica√ß√£o das m√©tricas
        st.markdown(f"""
        ### üìä Explica√ß√£o das M√©tricas (Limiar = {decision_threshold:.2f}):
        - **Acur√°cia**: Propor√ß√£o total de previs√µes corretas
        - **Precis√£o**: Dos casos previstos como inadimplentes, quantos realmente s√£o?
        - **Recall (Sensibilidade)**: Dos casos realmente inadimplentes, quantos foram identificados?
        - **Especificidade**: Dos casos realmente bons, quantos foram identificados corretamente?
        
        **Impacto do Limiar:**
        - Limiar mais **baixo**: Aprova mais empr√©stimos, mas aumenta risco de inadimpl√™ncia
        - Limiar mais **alto**: Rejeita mais empr√©stimos, mas reduz risco de inadimpl√™ncia
        """)
    
    # 4. Resumo do Modelo (Vers√£o personalizada j√° que statsmodels est√° causando problemas)
    st.subheader("5. Resumo das Estat√≠sticas de Regress√£o")
    with st.container():
        if 'custom_summary' in st.session_state:
            summary = st.session_state.custom_summary
            
            # Criar DataFrame para exibi√ß√£o de coeficientes
            coef_df = pd.DataFrame({
                'Vari√°vel': summary['features'],
                'Coeficiente': summary['coefficients'],
                'Raz√£o de Chances': np.exp(summary['coefficients'])
            })
            
            # Exibir informa√ß√µes do modelo
            st.markdown("### Informa√ß√µes do Modelo")
            st.markdown(f"""
            - **N√∫mero de observa√ß√µes:** {len(st.session_state.X_train)}
            - **N√∫mero de preditores:** {len(summary['features'])}
            - **Intercepto:** {summary['intercept']:.3f}
            - **Log Loss de Treinamento:** {summary['train_log_loss']:.3f}
            - **Acur√°cia de Treinamento:** {summary['train_accuracy']:.3f}
            - **Acur√°cia de Teste:** {summary['test_accuracy']:.3f}
            """)
            
            st.markdown("### Coeficientes")
            
            # Estiliza√ß√£o do DataFrame usando Pandas
            def style_table(df):
                df = df.reset_index(drop=True)
                
                return df.style.set_table_styles(
                    [{
                        'selector': 'thead th',
                        'props': [('font-weight', 'bold'),
                                ('border-style', 'solid'),
                                ('border-width', '0px 0px 2px 0px'),
                                ('border-color', 'black'),]
                    }, {
                        'selector': 'thead th:not(:first-child)',
                        'props': [('text-align', 'center')]  # Centralizar todos os cabe√ßalhos exceto o primeiro
                    }, {
                        'selector': 'thead th:last-child',
                        'props': [('color', 'black')]  # Fazer o cabe√ßalho da √∫ltima coluna preto
                    }, {
                        'selector': 'td',
                        'props': [('border-style', 'solid'),
                                ('border-width', '0px 0px 1px 0px'),
                                ('border-color', 'black'),
                                ('text-align', 'center')]
                    }, {
                        'selector': 'th',
                        'props': [('border-style', 'solid'),
                                ('border-width', '0px 0px 1px 0px'),
                                ('border-color', 'black'),
                                ('text-align', 'left'),]
                    }]
                ).set_properties(**{'padding': '2px',
                                    'font-size': '15px'})

            # Exibindo no Streamlit
            def main():
                styled_html = style_table(coef_df).to_html(index=False, escape=False)
                centered_html = f'''
                <div style="display: flex; justify-content: left;">
                    {styled_html}
                '''  # Fechar corretamente a tag div
                st.markdown(centered_html, unsafe_allow_html=True)

            if __name__ == '__main__':
                main()
            
            # Adicionar bot√£o de download para resumo
            summary_text = f"""
            Resumo do Modelo de Regress√£o Log√≠stica para Risco de Cr√©dito
            ============================================================
            
            Informa√ß√µes do Modelo:
            ----------------------
            N√∫mero de observa√ß√µes: {len(st.session_state.X_train)}
            N√∫mero de preditores: {len(summary['features'])}
            Intercepto: {summary['intercept']}
            Log Loss de Treinamento: {summary['train_log_loss']}
            Acur√°cia de Treinamento: {summary['train_accuracy']}
            Acur√°cia de Teste: {summary['test_accuracy']}
            
            Coeficientes:
            ------------
            """
            
            for feature, coef, odds in zip(summary['features'], summary['coefficients'], np.exp(summary['coefficients'])):
                summary_text += f"{feature}: {coef:.6f} (raz√£o de chances: {odds:.6f})\n"
            
            st.download_button(
                label="Baixar Resumo como Texto",
                data=summary_text,
                file_name="resumo_regressao_logistica.txt",
                mime="text/plain"
            )
        else:
            st.error("Estat√≠sticas de resumo do modelo n√£o est√£o dispon√≠veis. Por favor, treine o modelo primeiro.")
    
    # 5. Explica√ß√£o das estat√≠sticas
    st.subheader("6. Interpreta√ß√£o das Estat√≠sticas")
    with st.container():
        st.markdown("""
        **Principais estat√≠sticas e sua interpreta√ß√£o:**
        
        **Coeficiente (coef):** 
        - Indica a mudan√ßa no log-odds de inadimpl√™ncia para um aumento de uma unidade no preditor.
        - Coeficiente positivo: √Ä medida que o preditor aumenta, a probabilidade de inadimpl√™ncia aumenta.
        - Coeficiente negativo: √Ä medida que o preditor aumenta, a probabilidade de inadimpl√™ncia diminui.
        
        **Raz√£o de Chances:**
        - O coeficiente exponenciado (e^coef).
        - Representa como as chances de inadimpl√™ncia se multiplicam quando o preditor aumenta em uma unidade.
        - Raz√£o de Chances > 1: A vari√°vel aumenta o risco de inadimpl√™ncia.
        - Raz√£o de Chances < 1: A vari√°vel diminui o risco de inadimpl√™ncia.
        
        **Log Loss:**
        - Mede qu√£o bem as probabilidades previstas do modelo correspondem aos resultados reais.
        - Valores menores indicam melhor ajuste (menos incerteza).
        
        **Acur√°cia:**
        - Propor√ß√£o de previs√µes corretas (tanto empr√©stimos pagos quanto inadimplentes).
        - Valores maiores indicam melhor desempenho preditivo geral.
        
        **Interpretando Efeitos das Vari√°veis:**
        - A magnitude dos coeficientes indica a for√ßa do efeito.
        - Vari√°veis categ√≥ricas (como grau) mostram o efeito relativo a uma categoria de refer√™ncia.
        - Vari√°veis com coeficientes absolutos maiores t√™m efeitos mais fortes na probabilidade de inadimpl√™ncia.
        """)
    
    # 6. Equa√ß√£o de Regress√£o Log√≠stica
    st.subheader("7. Equa√ß√£o de Regress√£o Log√≠stica")
    with st.container():
        # Formatar a equa√ß√£o com melhor espa√ßamento e alinhamento
        st.markdown("""
        A equa√ß√£o de regress√£o log√≠stica (forma log-odds):
        """)
        
        # Construir equa√ß√£o dinamicamente usando coeficientes reais do modelo
        intercept_term = f"{st.session_state.intercept:.4f}"
        
        # Criar vers√£o em texto limpa
        text_equation = f"log(P(Inadimpl√™ncia)/(1-P(Inadimpl√™ncia))) = {intercept_term}"
        for feature, coef in zip(st.session_state.selected_features, st.session_state.coefficients):
            if coef >= 0:
                text_equation += f" + {coef:.4f} √ó {feature}"
            else:
                text_equation += f" {coef:.4f} √ó {feature}"
        
        st.code(text_equation, language=None)

        # Equa√ß√£o de probabilidade com melhor formata√ß√£o
        st.markdown("""
        **Probabilidade de Inadimpl√™ncia:**
        
        $\\large P(\\text{Inadimpl√™ncia}) = \\frac{1}{1 + e^{-z}}$
        
        Onde $z$ √© a equa√ß√£o log-odds acima.
        """)
        
        # Tabela de interpreta√ß√£o de coeficientes
        st.subheader("Interpreta√ß√£o dos Coeficientes")
        
        coef_df = pd.DataFrame({
            'Vari√°vel': st.session_state.selected_features,
            'Coeficiente': st.session_state.coefficients,
            'Raz√£o de Chances': np.exp(st.session_state.coefficients)
        })
        
        # Adicionar interpreta√ß√£o
        def get_interpretation(feature, coef, odds_ratio):
            if coef > 0:
                return f"Um aumento de uma unidade em {feature} multiplica as chances de inadimpl√™ncia por {odds_ratio:.3f} (aumenta em {(odds_ratio-1)*100:.1f}%)"
            else:
                return f"Um aumento de uma unidade em {feature} multiplica as chances de inadimpl√™ncia por {odds_ratio:.3f} (diminui em {(1-odds_ratio)*100:.1f}%)"
        
        coef_df['Interpreta√ß√£o'] = [
            get_interpretation(feature, coef, odds_ratio) 
            for feature, coef, odds_ratio in zip(
                coef_df['Vari√°vel'], coef_df['Coeficiente'], coef_df['Raz√£o de Chances']
            )
        ]
        
        # Estiliza√ß√£o do DataFrame usando Pandas
        def style_table(df):
            df = df.reset_index(drop=True)
            
            return df.style.set_table_styles(
                [{
                    'selector': 'thead th',
                    'props': [('font-weight', 'bold'),
                            ('border-style', 'solid'),
                            ('border-width', '0px 0px 2px 0px'),
                            ('border-color', 'black'),]
                }, {
                    'selector': 'thead th:not(:first-child)',
                    'props': [('text-align', 'center')]  # Centralizar todos os cabe√ßalhos exceto o primeiro
                }, {
                    'selector': 'thead th:last-child',
                    'props': [('color', 'black')]  # Fazer o cabe√ßalho da √∫ltima coluna preto
                }, {
                    'selector': 'td',
                    'props': [('border-style', 'solid'),
                            ('border-width', '0px 0px 1px 0px'),
                            ('border-color', 'black'),
                            ('text-align', 'center')]
                }, {
                    'selector': 'th',
                    'props': [('border-style', 'solid'),
                            ('border-width', '0px 0px 1px 0px'),
                            ('border-color', 'black'),
                            ('text-align', 'left'),]
                }]
            ).set_properties(**{'padding': '2px',
                                'font-size': '15px'})

        # Exibindo no Streamlit
        def main():
            styled_html = style_table(coef_df).to_html(index=False, escape=False)
            centered_html = f'''
            <div style="display: flex; justify-content: left;">
                {styled_html}
            '''  # Fechar corretamente a tag div
            st.markdown(centered_html, unsafe_allow_html=True)

        if __name__ == '__main__':
            main()                
        

# Previs√£o na Amostra de Teste
if 'model_trained' in st.session_state and st.session_state.model_trained:
    st.header("Analisar Potenciais Tomadores de Empr√©stimo")
    
    st.write("""
    Agora voc√™ pode analisar potenciais tomadores de empr√©stimo usando o modelo treinado.
    O modelo usar√° as mesmas vari√°veis que voc√™ selecionou para treinamento.
    """)
    
    # Verificar se as vari√°veis necess√°rias existem na amostra de teste
    missing_features = [f for f in st.session_state.original_features if f not in testing_sample.columns]
    
    if missing_features:
        st.error(f"A amostra de teste est√° faltando vari√°veis necess√°rias: {', '.join(missing_features)}")
    else:
        if st.button("Analisar Potenciais Tomadores de Empr√©stimo", key=2):
            with st.spinner("Analisando potenciais tomadores de empr√©stimo..."):
                # Preparar dados de teste usando as mesmas vari√°veis
                X_potential = testing_sample[st.session_state.original_features]
                
                # Fazer previs√µes
                potential_proba = st.session_state.model.predict_proba(X_potential)[:, 1]

                # Obter limiar do usu√°rio
                user_threshold = st.session_state.get('decision_threshold')
                potential_pred = (potential_proba >= user_threshold).astype(int)  # Usar limiar do usu√°rio
                
                # Adicionar previs√µes √† amostra de teste
                results_df = testing_sample.copy()
                results_df['probabilidade_prevista'] = potential_proba
                results_df['status_previsto'] = potential_pred
                
                # Armazenar previs√µes para compara√ß√£o posterior
                st.session_state.prediction_results = results_df
                
                # Exibir resultados
                st.subheader("Resultados das Previs√µes")
                
                # Estat√≠sticas resumidas
                approved_count = (potential_pred == 0).sum()
                rejected_count = (potential_pred == 1).sum()
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Empr√©stimos Aprovados", f"{approved_count} ({approved_count/len(potential_pred)*100:.1f}%)")
                with col2:
                    st.metric("Empr√©stimos Rejeitados", f"{rejected_count} ({rejected_count/len(potential_pred)*100:.1f}%)")
                
                # Distribui√ß√£o de probabilidades previstas
                st.subheader("Distribui√ß√£o das Probabilidades de Inadimpl√™ncia")
                fig, ax = plt.subplots(figsize=(10, 6))
                
                sns.histplot(potential_proba, bins=50, kde=True, ax=ax)
                ax.axvline(x=decision_threshold, color='red', linestyle='--')
                ax.text(decision_threshold+0.02, ax.get_ylim()[1]*0.9, f'Limiar de Decis√£o ({decision_threshold:.2f})', color='red')
                ax.set_xlabel('Probabilidade Prevista de Inadimpl√™ncia')
                ax.set_ylabel('Contagem')
                ax.set_title('Distribui√ß√£o das Probabilidades Previstas de Inadimpl√™ncia')
                
                col1, col2, col3 = st.columns([1, 6, 1])
                with col2:
                    st.pyplot(fig)        
                
                # Exibir tabela de resultados
                st.subheader("Resultados Detalhados")
                st.dataframe(results_df.sort_values('probabilidade_prevista', ascending=False))
                
                # Op√ß√£o de download
                csv = results_df.to_csv(index=False)
                st.download_button(
                    label="Baixar Resultados como CSV",
                    data=csv,
                    file_name='previsoes_potenciais_tomadores.csv',
                    mime='text/csv',
                )
                
                # An√°lise por n√≠vel de risco
                st.subheader("An√°lise por N√≠vel de Risco")
                
                # Criar n√≠veis de risco
                bins = [0, 0.2, 0.4, 0.6, 0.8, 1.0]
                labels = ['Risco Muito Baixo', 'Risco Baixo', 'Risco Moderado', 'Risco Alto', 'Risco Muito Alto']
                results_df['nivel_risco'] = pd.cut(results_df['probabilidade_prevista'], bins=bins, labels=labels)
                
                # Contar por n√≠vel
                tier_counts = results_df['nivel_risco'].value_counts().sort_index()
                
                # Exibir como gr√°fico de barras
                fig, ax = plt.subplots(figsize=(10, 6))
                tier_counts.plot(kind='bar', ax=ax, color=plt.cm.RdYlGn_r(np.linspace(0, 1, len(labels))))
                ax.set_xlabel('N√≠vel de Risco')
                ax.set_ylabel('N√∫mero de Potenciais Tomadores de Empr√©stimo')
                ax.set_title('Distribui√ß√£o de Potenciais Tomadores por N√≠vel de Risco')
                
                for i, v in enumerate(tier_counts):
                    ax.text(i, v + 5, f"{v} ({v/len(results_df)*100:.1f}%)", ha='center')
                
                col1, col2, col3 = st.columns([1, 6, 1])
                with col2:
                    st.pyplot(fig)        

    # Comparar previs√µes com resultados reais
    st.header("Comparar Previs√µes com Resultados Reais")
    
    st.write("""
    Esta se√ß√£o compara as previs√µes do modelo com os resultados reais dos empr√©stimos
    do arquivo testing_sample_true.csv.
    """)
    
    # Fun√ß√£o para carregar os dados verdadeiros de teste
    @st.cache_data
    def load_true_testing_data():
        try:
            # Tentar carregar o arquivo real
            testing_sample_true = pd.read_csv('testing_sample_true.csv')
            return testing_sample_true
        except:
            # Criar dados sint√©ticos de verdade para demonstra√ß√£o
            st.warning("Usando dados sint√©ticos de verdade. Em produ√ß√£o, conecte-se ao testing_sample_true.csv real")
            if 'prediction_results' in st.session_state:
                # Usar IDs dos resultados de previs√£o
                ids = st.session_state.prediction_results['id'].values
                n = len(ids)
                
                # Gerar verdade sint√©tica correlacionada com nossas previs√µes
                # mas n√£o perfeitamente correspondente (taxa de concord√¢ncia de 80%)
                if 'model' in st.session_state:
                    # Para demonstra√ß√£o: fazer verdade sint√©tica parcialmente correlacionada com previs√µes do modelo
                    predicted_probs = st.session_state.prediction_results['probabilidade_prevista'].values
                    
                    # Adicionar algum ru√≠do √†s probabilidades
                    noisy_probs = predicted_probs + np.random.normal(0, 0.15, n)
                    noisy_probs = np.clip(noisy_probs, 0, 1)
                    
                    # Converter para resultados bin√°rios
                    synthetic_outcomes = (noisy_probs > 0.5).astype(int)
                else:
                    # Se n√£o h√° previs√µes do modelo dispon√≠veis, gerar resultados aleat√≥rios com distribui√ß√£o realista
                    synthetic_outcomes = np.random.binomial(1, 0.2, n)  # Taxa de inadimpl√™ncia de 20%
                
                return pd.DataFrame({
                    'id': ids,
                    'loan_status': synthetic_outcomes
                })
    
    # Carregar os resultados verdadeiros
    testing_sample_true = load_true_testing_data()
    
    if 'prediction_results' not in st.session_state:
        st.info("Por favor, execute 'Analisar Potenciais Tomadores de Empr√©stimo' primeiro para gerar previs√µes.")
    else:
        # Mesclar previs√µes com resultados verdadeiros
        comparison_df = st.session_state.prediction_results[['id', 'status_previsto', 'probabilidade_prevista']].merge(
            testing_sample_true[['id', 'loan_status']], 
            on='id',
            how='inner'
        )
        
        if len(comparison_df) == 0:
            st.error("N√£o foi poss√≠vel corresponder nenhuma previs√£o com resultados verdadeiros. Verifique se os IDs correspondem entre os conjuntos de dados.")
        else:
            st.success(f"Correspond√™ncia bem-sucedida de {len(comparison_df)} empr√©stimos entre previs√µes e resultados reais.")
            
            # Calcular m√©tricas
            from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
            
            accuracy = accuracy_score(comparison_df['loan_status'], comparison_df['status_previsto'])
            precision = precision_score(comparison_df['loan_status'], comparison_df['status_previsto'])
            recall = recall_score(comparison_df['loan_status'], comparison_df['status_previsto'])
            f1 = f1_score(comparison_df['loan_status'], comparison_df['status_previsto'])
            roc_auc = roc_auc_score(comparison_df['loan_status'], comparison_df['probabilidade_prevista'])
            
            # Exibir m√©tricas
            st.subheader("Desempenho do Modelo nos Dados de Teste")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Acur√°cia", f"{accuracy:.4f}")
                st.metric("F1 Score", f"{f1:.4f}")
            with col2:
                st.metric("Precis√£o", f"{precision:.4f}")
                st.metric("ROC-AUC", f"{roc_auc:.4f}")
            with col3:
                st.metric("Recall", f"{recall:.4f}")
            
            # Adicionar explica√ß√£o das m√©tricas
            with st.expander("Entenda essas m√©tricas"):
                st.markdown("""
                - **Acur√°cia**: Porcentagem de previs√µes corretas (tanto empr√©stimos pagos quanto inadimplentes)
                - **Precis√£o**: Porcentagem de inadimpl√™ncias previstas que eram inadimpl√™ncias reais (menos falsos positivos)
                - **Recall**: Porcentagem de inadimpl√™ncias reais que foram corretamente previstas (menos falsos negativos)
                - **F1 Score**: M√©dia harm√¥nica de precis√£o e recall
                - **ROC-AUC**: √Årea sob a curva ROC, mede a capacidade do modelo de distinguir entre classes
                
                Na modelagem de risco de cr√©dito, diferentes m√©tricas podem ser priorizadas dependendo dos objetivos de neg√≥cio:
                - **Precis√£o** mais alta significa menos empr√©stimos bons s√£o incorretamente rejeitados
                - **Recall** mais alto significa menos empr√©stimos ruins s√£o incorretamente aprovados
                """)
            
            # Matriz de confus√£o
            st.subheader("Matriz de Confus√£o")
            cm = confusion_matrix(comparison_df['loan_status'], comparison_df['status_previsto'])
            
            fig, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                        xticklabels=['Previsto Pago', 'Previsto Inadimplente'],
                        yticklabels=['Realmente Pago', 'Realmente Inadimplente'])
            ax.set_xlabel('R√≥tulo Previsto')
            ax.set_ylabel('R√≥tulo Verdadeiro')
            ax.set_title('Matriz de Confus√£o nos Dados de Teste')
            col1, col2, col3 = st.columns([1, 6, 1])
            with col2:
                st.pyplot(fig)        
            
            # An√°lise de erros
            st.subheader("An√°lise de Erros")
            
            # Adicionar categorias de erro
            comparison_df['categoria_resultado'] = 'Desconhecido'
            comparison_df.loc[(comparison_df['status_previsto'] == 0) & (comparison_df['loan_status'] == 0), 'categoria_resultado'] = 'Verdadeiro Negativo (Pagamento Corretamente Previsto)'
            comparison_df.loc[(comparison_df['status_previsto'] == 1) & (comparison_df['loan_status'] == 1), 'categoria_resultado'] = 'Verdadeiro Positivo (Inadimpl√™ncia Corretamente Prevista)'
            comparison_df.loc[(comparison_df['status_previsto'] == 1) & (comparison_df['loan_status'] == 0), 'categoria_resultado'] = 'Falso Positivo (Inadimpl√™ncia Incorretamente Prevista)'
            comparison_df.loc[(comparison_df['status_previsto'] == 0) & (comparison_df['loan_status'] == 1), 'categoria_resultado'] = 'Falso Negativo (Pagamento Incorretamente Previsto)'
            
            # Contar por categoria
            result_counts = comparison_df['categoria_resultado'].value_counts()
            
            # Exibir como gr√°fico de pizza
            fig, ax = plt.subplots(figsize=(10, 8))
            colors = ['#4CAF50', '#2196F3', '#FFC107', '#F44336']
            result_counts.plot(kind='pie', autopct='%1.1f%%', ax=ax, colors=colors, textprops={'fontsize': 14})
            ax.set_ylabel('')
            ax.set_title('Distribui√ß√£o dos Resultados de Previs√£o')
            col1, col2, col3 = st.columns([1, 6, 1])
            with col2:
                st.pyplot(fig)        
            
            # Curva ROC
            st.subheader("Curva ROC nos Dados de Teste")
            fpr, tpr, _ = roc_curve(comparison_df['loan_status'], comparison_df['probabilidade_prevista'])
            
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.plot(fpr, tpr, 'b-', linewidth=2, label=f'Curva ROC (AUC = {roc_auc:.3f})')
            ax.plot([0, 1], [0, 1], 'r--', linewidth=1, label='Classificador Aleat√≥rio')
            ax.set_xlabel('Taxa de Falsos Positivos (1 - Especificidade)')
            ax.set_ylabel('Taxa de Verdadeiros Positivos (Sensibilidade)')
            ax.set_title('Curva ROC (Receiver Operating Characteristic) nos Dados de Teste')
            ax.legend(loc='lower right')
            ax.grid(True, alpha=0.3)
            col1, col2, col3 = st.columns([1, 6, 1])
            with col2:
                st.pyplot(fig)        
            
            # An√°lise detalhada de erros - mostrar os principais casos mal classificados
            st.subheader("Principais Casos Mal Classificados")
            
            # Falsos Positivos (erros Tipo I) - empr√©stimos bons rejeitados
            st.markdown("### Falsos Positivos (Empr√©stimos bons incorretamente previstos como inadimplentes)")
            fp_df = comparison_df[comparison_df['categoria_resultado'] == 'Falso Positivo (Inadimpl√™ncia Incorretamente Prevista)'].sort_values('probabilidade_prevista', ascending=False)
            if len(fp_df) > 0:
                st.dataframe(fp_df.head(10))
            else:
                st.info("Nenhum falso positivo encontrado.")
                
            # Falsos Negativos (erros Tipo II) - empr√©stimos ruins aprovados
            st.markdown("### Falsos Negativos (Empr√©stimos ruins incorretamente previstos como pagamentos)")
            fn_df = comparison_df[comparison_df['categoria_resultado'] == 'Falso Negativo (Pagamento Incorretamente Previsto)'].sort_values('probabilidade_prevista')
            if len(fn_df) > 0:
                st.dataframe(fn_df.head(10))
            else:
                st.info("Nenhum falso negativo encontrado.")
            
            # An√°lise de impacto nos neg√≥cios
            st.subheader("An√°lise de Impacto nos Neg√≥cios")
            
            # Na modelagem de cr√©dito, falsos negativos (aprovar empr√©stimos ruins) tipicamente custam mais que
            # falsos positivos (rejeitar empr√©stimos bons)
            fn_count = len(fn_df)
            fp_count = len(fp_df)
            
            # Estimar custos (para demonstra√ß√£o)
            avg_loan_amount = testing_sample['loan_amnt'].mean() if 'loan_amnt' in testing_sample.columns else 10000
            
            # Assumir taxa de perda em inadimpl√™ncias de cerca de 70% do principal
            estimated_fn_loss = fn_count * avg_loan_amount * 0.7
            
            # Assumir custo de oportunidade em falsos positivos de cerca de 10% do lucro potencial
            estimated_fp_loss = fp_count * avg_loan_amount * 0.1
            
            st.markdown(f"""
            ### Impacto Financeiro Estimado
            
            Baseado em um modelo de custo simples:
            
            - **Falsos Negativos (Aprovar empr√©stimos ruins):**
              - Contagem: {fn_count}
              - Perda estimada: R${estimated_fn_loss:,.2f}
              
            - **Falsos Positivos (Rejeitar empr√©stimos bons):**
              - Contagem: {fp_count}
              - Custo de oportunidade estimado: R${estimated_fp_loss:,.2f}
              
            - **Impacto total estimado:** R${estimated_fn_loss + estimated_fp_loss:,.2f}
            
            Nota: Esta √© uma estimativa simplificada para fins de demonstra√ß√£o. O impacto financeiro real
            exigiria an√°lise mais complexa incorporando taxas de juros, taxas de recupera√ß√£o, custos operacionais
            e custos de oportunidade.
            """)
            
            # An√°lise de limiar
            st.subheader("An√°lise do Limiar de Decis√£o")
            
            # Calcular m√©tricas em diferentes limiares
            thresholds = np.linspace(0.1, 0.9, 9)
            threshold_results = []
            
            for threshold in thresholds:
                pred_at_threshold = (comparison_df['probabilidade_prevista'] >= threshold).astype(int)
                acc = accuracy_score(comparison_df['loan_status'], pred_at_threshold)
                prec = precision_score(comparison_df['loan_status'], pred_at_threshold)
                rec = recall_score(comparison_df['loan_status'], pred_at_threshold)
                f1_score_val = f1_score(comparison_df['loan_status'], pred_at_threshold)
                
                # Contar FP e FN neste limiar
                fp = ((pred_at_threshold == 1) & (comparison_df['loan_status'] == 0)).sum()
                fn = ((pred_at_threshold == 0) & (comparison_df['loan_status'] == 1)).sum()
                
                # Custos estimados
                fn_cost = fn * avg_loan_amount * 0.7
                fp_cost = fp * avg_loan_amount * 0.1
                total_cost = fn_cost + fp_cost
                
                threshold_results.append({
                    'Limiar': threshold,
                    'Acur√°cia': acc,
                    'Precis√£o': prec,
                    'Recall': rec,
                    'F1 Score': f1_score_val,
                    'Falsos Positivos': fp,
                    'Falsos Negativos': fn,
                    'Custo Estimado': total_cost
                })
            
            threshold_df = pd.DataFrame(threshold_results)
            
            # Plotar m√©tricas vs limiar
            fig, ax1 = plt.subplots(figsize=(12, 6))
            
            # Plotar m√©tricas
            ax1.set_xlabel('Limiar de Decis√£o')
            ax1.set_ylabel('Valor da M√©trica')
            ax1.plot(threshold_df['Limiar'], threshold_df['Acur√°cia'], 'g-', label='Acur√°cia')
            ax1.plot(threshold_df['Limiar'], threshold_df['Precis√£o'], 'b-', label='Precis√£o')
            ax1.plot(threshold_df['Limiar'], threshold_df['Recall'], 'r-', label='Recall')
            ax1.plot(threshold_df['Limiar'], threshold_df['F1 Score'], 'y-', label='F1 Score')
            ax1.tick_params(axis='y')
            ax1.legend(loc='center left')
            ax1.grid(True, alpha=0.3)
            
            # Plotar custo estimado no eixo secund√°rio
            ax2 = ax1.twinx()
            ax2.set_ylabel('Custo Estimado (R$)', color='purple')
            ax2.plot(threshold_df['Limiar'], threshold_df['Custo Estimado'], 'm--', label='Custo Est.')
            ax2.tick_params(axis='y', labelcolor='purple')
            
            fig.tight_layout()
            ax1.set_title('Impacto do Limiar de Probabilidade no Desempenho do Modelo e Custo')
            
            # Adicionar marcador do limiar √≥timo
            optimal_idx = threshold_df['Custo Estimado'].idxmin()
            optimal_threshold = threshold_df.loc[optimal_idx, 'Limiar']
            ax1.axvline(x=optimal_threshold, color='black', linestyle='--', alpha=0.7)
            ax1.text(optimal_threshold+0.02, 0.5, f'Limiar √≥timo: {optimal_threshold:.2f}', 
                    transform=ax1.get_xaxis_transform(), fontsize=10)
            
            col1, col2, col3 = st.columns([1, 6, 1])
            with col2:
                st.pyplot(fig)        
            
            st.markdown(f"""
            ### Limiar de Decis√£o √ìtimo
            
            Baseado na an√°lise de custo, o limiar de decis√£o √≥timo √© aproximadamente **{optimal_threshold:.2f}**
            (comparado ao limiar padr√£o de 0.5).
            
            Neste limiar:
            - Acur√°cia: {threshold_df.loc[optimal_idx, 'Acur√°cia']:.4f}
            - Precis√£o: {threshold_df.loc[optimal_idx, 'Precis√£o']:.4f}
            - Recall: {threshold_df.loc[optimal_idx, 'Recall']:.4f}
            - Custo estimado: R${threshold_df.loc[optimal_idx, 'Custo Estimado']:,.2f}
            
            **Recomenda√ß√£o de neg√≥cio:** Considere ajustar o limiar de decis√£o baseado nas prioridades
            espec√≠ficas do neg√≥cio e apetite ao risco. Um limiar mais alto reduz inadimpl√™ncias mas aprova menos empr√©stimos,
            enquanto um limiar mais baixo aprova mais empr√©stimos mas aumenta o risco de inadimpl√™ncia.
            """)
            
            # Baixar resultados de compara√ß√£o
            st.download_button(
                label="Baixar Resultados de Compara√ß√£o",
                data=comparison_df.to_csv(index=False),
                file_name="comparacao_previsao_vs_real.csv",
                mime="text/csv"
            )


# Rodap√© com dicas para novos usu√°rios
st.markdown("---")
st.markdown("""
**Como usar esta ferramenta:**
1. Comece selecionando as vari√°veis nas caixas de sele√ß√£o
2. Clique em "Treinar Modelo de Regress√£o Log√≠stica" para ver os resultados
3. Analise o desempenho e as estat√≠sticas do modelo
4. Utilize o modelo para analisar potenciais tomadores de empr√©stimo
""")

# Rodap√©
st.divider()
st.caption("¬© 2025 Ferramenta de Modelagem de Risco de Cr√©dito | Desenvolvida com prop√≥sitos pedag√≥gicos")
st.caption("Prof. Jos√© Am√©rico ‚Äì Coppead")